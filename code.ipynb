{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4898289-6dc4-4cae-a371-b44cb744f60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ab931e7",
   "metadata": {},
   "source": [
    "# Run flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 Nothing\n",
    "# 0 Logs\n",
    "# 1 Rectangle boxes\n",
    "# 2 Show classified faces\n",
    "DEBUG = -1\n",
    "# Choose cosine similarity and fast method\n",
    "FAST = True\n",
    "# Delete Output/ folder files at the end\n",
    "DELETE = False\n",
    "# Stop video classifier at a certain frame\n",
    "# > 0 \n",
    "STOP_FRAME = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade_alt_tree   = cv2.CascadeClassifier('Models/haarcascade/haarcascade_frontalface_alt_tree.xml')\n",
    "face_cascade_alt        = cv2.CascadeClassifier('Models/haarcascade/haarcascade_frontalface_alt.xml')\n",
    "face_cascade_alt2       = cv2.CascadeClassifier('Models/haarcascade/haarcascade_frontalface_alt2.xml')\n",
    "face_cascade_default    = cv2.CascadeClassifier('Models/haarcascade/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f880f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('Dataset/Youtube/train.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_interval = 5\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frames_to_skip = int(frame_interval * fps)\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "saved_faces_counter = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6eaabc2a",
   "metadata": {},
   "source": [
    "# Faster one classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAST == True:\n",
    "    while video.isOpened:\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if STOP_FRAME > 0:\n",
    "            if frame_counter >= STOP_FRAME:\n",
    "                break\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % frames_to_skip != 0:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces_alt       = face_cascade_alt.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=6)\n",
    "        if DEBUG == 0:\n",
    "            print('Alt      - Number of detected faces:', len(faces_alt))\n",
    "\n",
    "        for i, (x, y, w, h) in enumerate(faces_alt):\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            cv2.imwrite(f'Output/face-{saved_faces_counter}.jpg', face)\n",
    "            if DEBUG == 1:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            if DEBUG == 2:\n",
    "                cv2.imshow(f\"Cropped Face {i}\", face) \n",
    "            saved_faces_counter += 1\n",
    "\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        if DEBUG == 0:\n",
    "            current_timestamp = timedelta(seconds=int(frame_counter / fps))\n",
    "            print(\"Current Timestamp:\", current_timestamp)\n",
    "\n",
    "        next_frame = int(frame_counter + frames_to_skip)\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, next_frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f9a3a64",
   "metadata": {},
   "source": [
    "# Slower and accurate 3 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAST == False:\n",
    "    while video.isOpened:\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if STOP_FRAME > 0:\n",
    "            if frame_counter >= STOP_FRAME:\n",
    "                break\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % frames_to_skip != 0:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces_alt       = face_cascade_alt.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=6)\n",
    "        faces_alt2      = face_cascade_alt2.detectMultiScale(gray, scaleFactor=1.4, minNeighbors=4)\n",
    "        faces_default   = face_cascade_default.detectMultiScale(gray, scaleFactor=1.4, minNeighbors=6)  \n",
    "\n",
    "        if DEBUG == 0:\n",
    "            print('Alt      - Number of detected faces:', len(faces_alt))\n",
    "            print('Alt2     - Number of detected faces:', len(faces_alt2))\n",
    "            print('Default  - Number of detected faces:', len(faces_default))\n",
    "\n",
    "        if DEBUG == 1:\n",
    "            for (x, y, w, h) in faces_alt:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            \n",
    "            for (x, y, w, h) in faces_alt2:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "\n",
    "            for (x, y, w, h) in faces_default:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 255), 2)\n",
    "\n",
    "        if len(faces_alt) > 0 and len(faces_alt2) > 0 and len(faces_default) > 0:\n",
    "            for face1_index, (x1, y1, w1, h1) in enumerate(faces_alt):\n",
    "                face1 = gray[y1:y1+h1, x1:x1+w1]\n",
    "                face1_resized = cv2.resize(face1, (64, 64))\n",
    "                face1_flattened = face1_resized.flatten()\n",
    "                face1_reshaped = face1_flattened.reshape(1, -1)\n",
    "\n",
    "                for face2_index, (x2, y2, w2, h2) in enumerate(faces_alt2):\n",
    "                    face2 = gray[y2:y2+h2, x2:x2+w2]\n",
    "                    face2_resized = cv2.resize(face2, (64, 64))\n",
    "                    face2_flattened = face2_resized.flatten()\n",
    "                    face2_reshaped = face2_flattened.reshape(1, -1)\n",
    "\n",
    "                    for face3_index, (x3, y3, w3, h3) in enumerate(faces_default):\n",
    "                        face3 = gray[y3:y3+h3, x3:x3+w3]\n",
    "                        face3_resized = cv2.resize(face3, (64, 64))\n",
    "                        face3_flattened = face3_resized.flatten()\n",
    "                        face3_reshaped = face3_flattened.reshape(1, -1)\n",
    "\n",
    "                        similarity12 = cosine_similarity(face1_reshaped, face2_reshaped)[0, 0]\n",
    "                        similarity13 = cosine_similarity(face1_reshaped, face3_reshaped)[0, 0]\n",
    "                        similarity23 = cosine_similarity(face2_reshaped, face3_reshaped)[0, 0]\n",
    "\n",
    "                        if similarity12 > 0.9 and similarity13 > 0.9 and similarity23 > 0.9:\n",
    "                            if DEBUG == 0:\n",
    "                                print(f'''\n",
    "                                    F1: {str(face1_index)} \n",
    "                                    F2: {str(face2_index)}\n",
    "                                    F3: {str(face3_index)} \n",
    "                                    Sim 1, 2: {str(similarity12)}\n",
    "                                    Sim 1, 3: {str(similarity13)}\n",
    "                                    Sim 2, 3: {str(similarity23)}\n",
    "                                ''')\n",
    "\n",
    "                            _max = max(similarity12, similarity13, similarity23)\n",
    "\n",
    "                            if similarity12 == _max:\n",
    "                                x1, y1, w1, h1\n",
    "                                face = frame[y1:y1+h1, x1:x1+w1]\n",
    "                            elif similarity13 == _max:\n",
    "                                x2, y2, w2, h2\n",
    "                                face = frame[y2:y2+h2, x2:x2+w2]\n",
    "                            elif similarity23 == _max:\n",
    "                                face = frame[y3:y3+h3, x3:x3+w3]\n",
    "                                x3, y3, w3, h3\n",
    "\n",
    "                            if DEBUG == 2:\n",
    "                                cv2.imshow(f\"Cropped Face {i}\", face)\n",
    "                            cv2.imwrite(f'Output/face-{saved_faces_counter}.jpg', face)\n",
    "                            saved_faces_counter += 1\n",
    "\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        if DEBUG == 0:\n",
    "            current_timestamp = timedelta(seconds=int(frame_counter / fps))\n",
    "            print(\"Current Timestamp:\", current_timestamp)\n",
    "\n",
    "        next_frame = int(frame_counter + frames_to_skip)\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, next_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_model = tf.keras.models.load_model('Models/vgg16/finetuning_vgg16_cnn_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "745a1b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.6182890e-03, 1.6386960e-02, 1.0417962e-06, 1.3972180e-02,\n",
       "        2.1472368e-07, 9.6202129e-01]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Output/face-2.jpg')\n",
    "\n",
    "if DEBUG == 0:\n",
    "    image.shape\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "IMAGE_SIZE = (150, 150)\n",
    "image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "if DEBUG == 0:\n",
    "    image.shape\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "image_array = np.array(image)/255.0\n",
    "image_array = image_array[np.newaxis, ...]\n",
    "\n",
    "if DEBUG == 0:\n",
    "    image_array.shape\n",
    "\n",
    "result = spl_model.predict(image_array)\n",
    "\n",
    "if DEBUG == 0:\n",
    "    result.shape\n",
    "\n",
    "# result\n",
    "\n",
    "predicted_label_index = np.argmax(result)\n",
    "# predicted_label_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08222ad3",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DELETE == True:\n",
    "    folder = 'Output'\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {str(file_path)}. Reason: {str(e)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
